{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x208a3ce89d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Data and Analysis Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Pytorch to train data\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "# Enable anomaly detection\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data To Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good and interesting</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107013</th>\n",
       "      <td>107013</td>\n",
       "      <td>Trendy topic with talks from expertises in the...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107014</th>\n",
       "      <td>107014</td>\n",
       "      <td>Wonderful! Simple and clear language, good ins...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107015</th>\n",
       "      <td>107015</td>\n",
       "      <td>an interesting and fun course. thanks. dr quincy</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107016</th>\n",
       "      <td>107016</td>\n",
       "      <td>very broad perspective, up to date information...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107017</th>\n",
       "      <td>107017</td>\n",
       "      <td>An informative course on the social and financ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107018 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                             Review  Label\n",
       "0            0                               good and interesting      5\n",
       "1            1  This class is very helpful to me. Currently, I...      5\n",
       "2            2  like!Prof and TAs are helpful and the discussi...      5\n",
       "3            3  Easy to follow and includes a lot basic and im...      5\n",
       "4            4  Really nice teacher!I could got the point eazl...      4\n",
       "...        ...                                                ...    ...\n",
       "107013  107013  Trendy topic with talks from expertises in the...      4\n",
       "107014  107014  Wonderful! Simple and clear language, good ins...      5\n",
       "107015  107015   an interesting and fun course. thanks. dr quincy      5\n",
       "107016  107016  very broad perspective, up to date information...      4\n",
       "107017  107017  An informative course on the social and financ...      4\n",
       "\n",
       "[107018 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/reviews.csv',  \n",
    "                 low_memory=False)\n",
    "df\n",
    "# reset index\n",
    "# df.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>good and interesting</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                             Review  Label\n",
       "0   0                               good and interesting      5\n",
       "1   1  This class is very helpful to me. Currently, I...      5\n",
       "2   2  like!Prof and TAs are helpful and the discussi...      5\n",
       "3   3  Easy to follow and includes a lot basic and im...      5\n",
       "4   4  Really nice teacher!I could got the point eazl...      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good and interesting</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Text  Score\n",
       "0   1                               good and interesting      5\n",
       "1   2  This class is very helpful to me. Currently, I...      5\n",
       "2   3  like!Prof and TAs are helpful and the discussi...      5\n",
       "3   4  Easy to follow and includes a lot basic and im...      5\n",
       "4   5  Really nice teacher!I could got the point eazl...      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.rename(columns={'Review': 'Text', 'Label': 'Score'})\n",
    "df['Id'] = df['Id'] + 1 \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông tin DataFrame:\n",
    "\n",
    "- **Chỉ số (Index):** Range từ 0 đến 568453 (tổng cộng 568454 dòng).\n",
    "- **Số cột:** 3 cột (\"Id\", \"Score\", \"Text\").\n",
    "- **Kiểu dữ liệu cột:**\n",
    "  - \"Id\" và \"Score\": int64.\n",
    "  - \"Text\": object (chuỗi hoặc đối tượng không phải số).\n",
    "- **Giá trị không phải null:**\n",
    "  - Mỗi cột có 568454 giá trị không phải null.\n",
    "- **Dung lượng bộ nhớ:** Khoảng 13.0 MB.\n",
    "\n",
    "> 568454 - 568427 = 27 giá trị null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107018 entries, 0 to 107017\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Id      107018 non-null  int64 \n",
      " 1   Text    107018 non-null  object\n",
      " 2   Score   107018 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info Data:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df`: Đây là tên của DataFrame, giả sử đã được định nghĩa trước đó trong mã.\n",
    "\n",
    "- `df.Text`: Lấy cột có tên \"Text\" từ DataFrame `df`.\n",
    "\n",
    "- `.iloc[10]`: Lấy giá trị ở dòng thứ 10 của cột \"Text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Is there any reason why you should not apply the course by BCG?)It's content is pretty unique and includes a high level analysis and a wide range of knowledge needed to cover all detailed aspects.Best regards,Oleg Serov\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null:\n",
    "df.Text.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id       0\n",
       "Text     0\n",
       "Score    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Xử lý xong các giá trị null, nếu có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107018 entries, 0 to 107017\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Id      107018 non-null  int64 \n",
      " 1   Text    107018 non-null  object\n",
      " 2   Score   107018 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# delete null values\n",
    "# Xóa các dòng có giá trị null\n",
    "df = df.dropna(subset=['Text'])\n",
    "# check for null\n",
    "df.isnull().sum()\n",
    "# Info Data:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "5    79173\n",
       "4    18054\n",
       "3     5071\n",
       "1     2469\n",
       "2     2251\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reduce data:\n",
    "# indices_to_remove = df[df['Score'] == 1].index[1:50000]\n",
    "# df = df.drop(indices_to_remove)\n",
    "# # Reduce data:\n",
    "# indices_to_remove = df[df['Score'] == 2].index[1:27500]\n",
    "# df = df.drop(indices_to_remove)\n",
    "# # Reduce data:\n",
    "# indices_to_remove = df[df['Score'] == 3].index[1:40000]\n",
    "# df = df.drop(indices_to_remove)\n",
    "# # Reduce data:\n",
    "# indices_to_remove = df[df['Score'] == 4].index[1:78000]\n",
    "# df = df.drop(indices_to_remove)\n",
    "# # Reduce data:\n",
    "# indices_to_remove = df[df['Score'] == 5].index[1:361000]\n",
    "# df = df.drop(indices_to_remove)\n",
    "# df.Score.value_counts()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lấy Series từ df['Score'].value_counts()\n",
    "score_counts = df['Score'].value_counts()\n",
    "\n",
    "# Thiết lập môi trường trực quan\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# Vẽ biểu đồ thanh\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=score_counts.index, y=score_counts.values,\n",
    "            palette=\"Spectral\", legend=False, hue=score_counts.values)\n",
    "plt.title('Score Reviews')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  7766\n"
     ]
    }
   ],
   "source": [
    "# find the maximum length\n",
    "max_len = max([len(text) for text in df.Text])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spliting into Train, Test, Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **`from sklearn.model_selection import train_test_split`**: \n",
    "   - Nhập hàm `train_test_split` từ scikit-learn để thực hiện chia dữ liệu thành tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "2. **`X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Score.values, test_size=0.15, random_state=17, stratify=df.Score.values)`**:\n",
    "   - `df.index.values`: Chọn cột chỉ mục của DataFrame (`index`), giả sử rằng nó chứa các giá trị duy nhất hoặc độc lập.\n",
    "   - `df.Score.values`: Chọn cột \"Score\" làm giá trị mục tiêu.\n",
    "   - `test_size=0.15`: Thiết lập tỷ lệ tập kiểm tra là 15%, tỷ lệ tập huấn luyện là 85%.\n",
    "   - `random_state=17`: Đặt một giá trị ngẫu nhiên để đảm bảo tái tạo kết quả nếu bạn muốn chạy lại mã và nhận được kết quả giống nhau.\n",
    "   - `stratify=df.Score.values`: Thiết lập để đảm bảo phân phối của tập kiểm tra giữ nguyên tỷ lệ của các lớp (stratified sampling), đặc biệt quan trọng nếu dữ liệu không cân bằng theo các giá trị của \"Score\".\n",
    "\n",
    "3. **`X_train, X_val, y_train, y_val`**:\n",
    "   - `X_train`, `X_val`: Chứa các chỉ mục (index) của dữ liệu tương ứng trong tập huấn luyện và tập kiểm tra.\n",
    "   - `y_train`, `y_val`: Chứa các giá trị \"Score\" tương ứng với tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "Tổng cộng, đoạn mã này chia dữ liệu thành tập huấn luyện và tập kiểm tra, sử dụng 85% dữ liệu cho tập huấn luyện và 15% cho tập kiểm tra, và giữ nguyên tỷ lệ của các lớp trong quá trình chia dữ liệu. Điều này làm cho mô hình có thể học từ một phân phối dữ liệu tương tự như dữ liệu gốc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>good and interesting</td>\n",
       "      <td>5</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This class is very helpful to me. Currently, I...</td>\n",
       "      <td>5</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>like!Prof and TAs are helpful and the discussi...</td>\n",
       "      <td>5</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Easy to follow and includes a lot basic and im...</td>\n",
       "      <td>5</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Really nice teacher!I could got the point eazl...</td>\n",
       "      <td>4</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Text  Score data_type\n",
       "0   1                               good and interesting      5   not_set\n",
       "1   2  This class is very helpful to me. Currently, I...      5   not_set\n",
       "2   3  like!Prof and TAs are helpful and the discussi...      5   not_set\n",
       "3   4  Easy to follow and includes a lot basic and im...      5   not_set\n",
       "4   5  Really nice teacher!I could got the point eazl...      4   not_set"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
    "                                                  df.Score.values,\n",
    "                                                  test_size=0.15,\n",
    "                                                  random_state=17,\n",
    "                                                  stratify=df.Score.values)\n",
    "# create new column\n",
    "df['data_type'] = ['not_set'] * df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in data type\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>2099</td>\n",
       "      <td>2099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>1913</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>4310</td>\n",
       "      <td>4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>761</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>15346</td>\n",
       "      <td>15346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2708</td>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>67297</td>\n",
       "      <td>67297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>11876</td>\n",
       "      <td>11876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id   Text\n",
       "Score data_type              \n",
       "1     train       2099   2099\n",
       "      val          370    370\n",
       "2     train       1913   1913\n",
       "      val          338    338\n",
       "3     train       4310   4310\n",
       "      val          761    761\n",
       "4     train      15346  15346\n",
       "      val         2708   2708\n",
       "5     train      67297  67297\n",
       "      val        11876  11876"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Score','data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **`from transformers import BertTokenizer`**:\n",
    "   - `BertTokenizer` là một lớp từ thư viện Transformers của Hugging Face, được thiết kế để chuyển đổi văn bản thành đầu vào mà mô hình BERT có thể hiểu được. Nó cung cấp các phương thức để mã hóa văn bản thành các token và thêm các thông tin đặc biệt như token đặc biệt `[CLS]` và `[SEP]` sử dụng trong mô hình BERT.\n",
    "\n",
    "2. **`from torch.utils.data import TensorDataset`**:\n",
    "   - `TensorDataset` là một lớp từ thư viện torch, được sử dụng để tạo dataset cho PyTorch. Đây là một cách thuận tiện để tổ chức dữ liệu và truyền nó vào mô hình PyTorch. Lớp này chấp nhận một hoặc nhiều tensors và tạo ra một dataset với khả năng lập chỉ mục dữ liệu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Text'].apply(lambda x: len(str(x)) < 512)]\n",
    "max_len_text = max(len(text) for text in df.Text)\n",
    "max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big_Project\\Mashine-Learning---RoBerta---Base-Bert\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize train set\n",
    "encoded_train_data = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Text.values,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 return_attention_mask=True,\n",
    "                                                 pad_to_max_length=True,\n",
    "                                                 max_length=max_len_text+1,\n",
    "                                                 return_tensors='pt',\n",
    "                                                 truncation=True)\n",
    "                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer val set\n",
    "encoded_data_val = tokenizer.batch_encode_plus(df[df.data_type == 'val'].Text.values,\n",
    "                                               # add_special_tokens = True,\n",
    "                                               return_attention_mask=True,\n",
    "                                               pad_to_max_length=True,\n",
    "                                               max_length=max_len_text+1,\n",
    "                                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2204,  1998,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  2465,  ...,     0,     0,     0],\n",
       "        [  101,  2066,   999,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2019,  5875,  ...,     0,     0,     0],\n",
       "        [  101,  2200,  5041,  ...,     0,     0,     0],\n",
       "        [  101,  2019, 12367,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode train set\n",
    "input_ids_train = encoded_train_data['input_ids']\n",
    "attention_masks_train = encoded_train_data['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == 'train'].Score.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode val set\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "\n",
    "# convert data type to torch.tensor\n",
    "labels_val = torch.tensor(df[df.data_type == 'val'].Score.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2204,  1998,  ...,     0,     0,     0],\n",
       "        [  101,  2023,  2465,  ...,     0,     0,     0],\n",
       "        [  101,  2066,   999,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2019,  5875,  ...,     0,     0,     0],\n",
       "        [  101,  2200,  5041,  ...,     0,     0,     0],\n",
       "        [  101,  2019, 12367,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5,  ..., 5, 4, 4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataset_train = TensorDataset(input_ids_train,\n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val,\n",
    "                            attention_masks_val,\n",
    "                            labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87454\n",
      "15415\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<torch.utils.data.dataset.TensorDataset object at 0x00000208B846E6D0>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2204,  1998,  ...,     0,     0,     0],\n",
       "         [  101,  2023,  2465,  ...,     0,     0,     0],\n",
       "         [  101,  2066,   999,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2019,  5875,  ...,     0,     0,     0],\n",
       "         [  101,  2200,  5041,  ...,     0,     0,     0],\n",
       "         [  101,  2019, 12367,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([5, 5, 5,  ..., 5, 4, 4]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Model Pretrained (*.pt Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU or CPU :\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Đường dẫn đến tệp .pt đã lưu\n",
    "model_path = '../model/pretrained_bert_model_1_2500.pt'\n",
    "\n",
    "# Khởi tạo mô hình BERT cho phân loại chuỗi và tải trạng thái từ tệp đã lưu\n",
    "load_model = torch.load(model_path)\n",
    "\n",
    "load_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "# We Need two different dataloder\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=2,\n",
    "                                pin_memory=True\n",
    "\n",
    "                              )\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=RandomSampler(dataset_val),\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=2,\n",
    "                                   pin_memory=True\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21864"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setting Up Optimiser and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=load_model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Big_Project\\Mashine-Learning---RoBerta---Base-Bert\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "\n",
    "    # Setting up the preds to axis=1\n",
    "    # Flatting it to a single iterable list of array\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "\n",
    "    # Flattening the labels\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Returning the f1_score as define by sklearn\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'sad': 2,\n",
    "              'worry': 3,\n",
    "              'so sad': 1,\n",
    "              'happy': 4,\n",
    "              'so happy': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    acc_avg = 0\n",
    "\n",
    "    # Iterating over all the unique labels\n",
    "    # label_flat are the --> True labels\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Taking out all the pred_flat where the True alable is the lable we care about.\n",
    "        # e.g. for the label Happy -- we Takes all Prediction for true happy flag\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')\n",
    "        acc_avg+=len(y_preds[y_preds == label])/len(y_true)\n",
    "        print(f'Accuracy Score: {accuracy_score(y_true, y_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create a training loop to control PyTorch finetuning of BERT using CPU or GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.35.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "model=load_model\n",
    "model.to(device)\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val, model=model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    cnt_batch = 0\n",
    "\n",
    "    for batch in tqdm(dataloader_val):\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                  }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "        # cnt_batch+=1\n",
    "        # if cnt_batch > 500:\n",
    "        #     break\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messure step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe86bfaf718423f98854848ab4df29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/21864 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02817581046906467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49db736ffbd04931a9796409ffb90d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.07587092127443157\n",
      "F1 Score (weighted): 0.8001972813545337\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    # Clear out the cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Tracking variable\n",
    "    loss_train_total = 0\n",
    "    print(f'Epoch {epoch}')\n",
    "    # set up progress bar\n",
    "    progress_bar = tqdm(dataloader_train,\n",
    "                        desc='Epoch {:1d}'.format(epoch),\n",
    "                        leave=False,\n",
    "                        disable=False)\n",
    "    cnt = 1\n",
    "    for batch in progress_bar:\n",
    "        # Set gradient to 0\n",
    "        model.zero_grad()\n",
    "        # Load into GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        # Define inputs\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]  # output.loss\n",
    "        loss_train_total += loss.item()\n",
    "        # Backward pass to get gradients\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update optimizer\n",
    "        optimizer.step()\n",
    "        # Update scheduler\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Print training loss print each lines\n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "        # Clear out the cache\n",
    "        del batch\n",
    "        del inputs\n",
    "        del outputs\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        if cnt == 1000:\n",
    "            break\n",
    "\n",
    "        cnt += 1\n",
    "    \n",
    "\n",
    "\n",
    "    model_save_path = f'../model/pretrained_bert_model_{epoch}.pt'\n",
    "\n",
    "    torch.save(model, model_save_path)\n",
    "\n",
    "\n",
    "    # Print training result\n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "\n",
    "    print(f'Training loss: {loss_train_avg}')\n",
    "    # Evaluate\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    # F1 score\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "    print(f'F1 Score (weighted): {val_f1}')\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Đường dẫn đến tệp .pt đã lưu\n",
    "model_path = '../model/pretrained_bert_model_1.pt'\n",
    "\n",
    "# Khởi tạo mô hình BERT cho phân loại chuỗi và tải trạng thái từ tệp đã lưu\n",
    "load_model = torch.load(model_path)\n",
    "\n",
    "load_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92e3e4491a64414b69c7c2afcbd7e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3854 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate\n",
    "_, predictions, true_vals = evaluate(dataloader_validation, load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: so sad\n",
      "Accuracy: 21/32\n",
      "\n",
      "Accuracy Score: 0.65625\n",
      "Class: sad\n",
      "Accuracy: 2/37\n",
      "\n",
      "Accuracy Score: 0.05405405405405406\n",
      "Class: worry\n",
      "Accuracy: 41/97\n",
      "\n",
      "Accuracy Score: 0.422680412371134\n",
      "Class: happy\n",
      "Accuracy: 99/316\n",
      "\n",
      "Accuracy Score: 0.31329113924050633\n",
      "Class: so happy\n",
      "Accuracy: 1480/1522\n",
      "\n",
      "Accuracy Score: 0.9724047306176085\n"
     ]
    }
   ],
   "source": [
    "#get accuracy score\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
