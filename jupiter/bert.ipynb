{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x21ab25215e0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize Data and Analysis Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Pytorch to train data\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "# Enable anomaly detection\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data To Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./data/Reviews.csv',  \n",
    "                 low_memory=False)\n",
    "df = df[[\"Id\", \"Score\", \"Summary\"]]\n",
    "df = df.rename(columns={'Summary': 'Text'})\n",
    "# reset index\n",
    "# df.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Score                   Text\n",
       "0   1      5  Good Quality Dog Food\n",
       "1   2      1      Not as Advertised\n",
       "2   3      4  \"Delight\" says it all\n",
       "3   4      2         Cough Medicine\n",
       "4   5      5            Great taffy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông tin DataFrame:\n",
    "\n",
    "- **Chỉ số (Index):** Range từ 0 đến 568453 (tổng cộng 568454 dòng).\n",
    "- **Số cột:** 3 cột (\"Id\", \"Score\", \"Text\").\n",
    "- **Kiểu dữ liệu cột:**\n",
    "  - \"Id\" và \"Score\": int64.\n",
    "  - \"Text\": object (chuỗi hoặc đối tượng không phải số).\n",
    "- **Giá trị không phải null:**\n",
    "  - Mỗi cột có 568454 giá trị không phải null.\n",
    "- **Dung lượng bộ nhớ:** Khoảng 13.0 MB.\n",
    "\n",
    "> 568454 - 568427 = 27 giá trị null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Id      568454 non-null  int64 \n",
      " 1   Score   568454 non-null  int64 \n",
      " 2   Text    568427 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 13.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Info Data:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `df`: Đây là tên của DataFrame, giả sử đã được định nghĩa trước đó trong mã.\n",
    "\n",
    "- `df.Text`: Lấy cột có tên \"Text\" từ DataFrame `df`.\n",
    "\n",
    "- `.iloc[10]`: Lấy giá trị ở dòng thứ 10 của cột \"Text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Best Hot Sauce in the World'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null:\n",
    "df.Text.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id        0\n",
       "Score     0\n",
       "Text     27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Xử lý xong các giá trị null, nếu có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 568427 entries, 0 to 568453\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Id      568427 non-null  int64 \n",
      " 1   Score   568427 non-null  int64 \n",
      " 2   Text    568427 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 17.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# delete null values\n",
    "# Xóa các dòng có giá trị null\n",
    "df = df.dropna(subset=['Text'])\n",
    "# check for null\n",
    "df.isnull().sum()\n",
    "# Info Data:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Score\n",
       "5    363122\n",
       "4     80655\n",
       "1     52268\n",
       "3     42638\n",
       "2     29744\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11932 entries, 0 to 568453\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Id      11932 non-null  int64 \n",
      " 1   Score   11932 non-null  int64 \n",
      " 2   Text    11932 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 372.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Reduce data:\n",
    "indices_to_remove = df[df['Score'] == 1].index[1:40000]\n",
    "df = df.drop(indices_to_remove)\n",
    "# Reduce data:\n",
    "indices_to_remove = df[df['Score'] == 2].index[1:20000]\n",
    "df = df.drop(indices_to_remove)\n",
    "# Reduce data:\n",
    "indices_to_remove = df[df['Score'] == 3].index[1:30000]\n",
    "df = df.drop(indices_to_remove)\n",
    "# Reduce data:\n",
    "indices_to_remove = df[df['Score'] == 4].index[1:70000]\n",
    "df = df.drop(indices_to_remove)\n",
    "# Reduce data:\n",
    "indices_to_remove = df[df['Score'] == 5].index[1:350000]\n",
    "df = df.drop(indices_to_remove)\n",
    "df.Score.value_counts()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lấy Series từ df['Score'].value_counts()\n",
    "score_counts = df['Score'].value_counts()\n",
    "\n",
    "# Thiết lập môi trường trực quan\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "# Vẽ biểu đồ thanh\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=score_counts.index, y=score_counts.values,\n",
    "            palette=\"Spectral\", legend=False, hue=score_counts.values)\n",
    "plt.title('Score Reviews')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Quantity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  126\n"
     ]
    }
   ],
   "source": [
    "# find the maximum length\n",
    "max_len = max([len(text) for text in df.Text])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Spliting into Train, Test, Val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **`from sklearn.model_selection import train_test_split`**: \n",
    "   - Nhập hàm `train_test_split` từ scikit-learn để thực hiện chia dữ liệu thành tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "2. **`X_train, X_val, y_train, y_val = train_test_split(df.index.values, df.Score.values, test_size=0.15, random_state=17, stratify=df.Score.values)`**:\n",
    "   - `df.index.values`: Chọn cột chỉ mục của DataFrame (`index`), giả sử rằng nó chứa các giá trị duy nhất hoặc độc lập.\n",
    "   - `df.Score.values`: Chọn cột \"Score\" làm giá trị mục tiêu.\n",
    "   - `test_size=0.15`: Thiết lập tỷ lệ tập kiểm tra là 15%, tỷ lệ tập huấn luyện là 85%.\n",
    "   - `random_state=17`: Đặt một giá trị ngẫu nhiên để đảm bảo tái tạo kết quả nếu bạn muốn chạy lại mã và nhận được kết quả giống nhau.\n",
    "   - `stratify=df.Score.values`: Thiết lập để đảm bảo phân phối của tập kiểm tra giữ nguyên tỷ lệ của các lớp (stratified sampling), đặc biệt quan trọng nếu dữ liệu không cân bằng theo các giá trị của \"Score\".\n",
    "\n",
    "3. **`X_train, X_val, y_train, y_val`**:\n",
    "   - `X_train`, `X_val`: Chứa các chỉ mục (index) của dữ liệu tương ứng trong tập huấn luyện và tập kiểm tra.\n",
    "   - `y_train`, `y_val`: Chứa các giá trị \"Score\" tương ứng với tập huấn luyện và tập kiểm tra.\n",
    "\n",
    "Tổng cộng, đoạn mã này chia dữ liệu thành tập huấn luyện và tập kiểm tra, sử dụng 85% dữ liệu cho tập huấn luyện và 15% cho tập kiểm tra, và giữ nguyên tỷ lệ của các lớp trong quá trình chia dữ liệu. Điều này làm cho mô hình có thể học từ một phân phối dữ liệu tương tự như dữ liệu gốc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>Hearty Oatmeal</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Score                   Text data_type\n",
       "0    1      5  Good Quality Dog Food   not_set\n",
       "1    2      1      Not as Advertised   not_set\n",
       "2    3      4  \"Delight\" says it all   not_set\n",
       "3    4      2         Cough Medicine   not_set\n",
       "45  46      3         Hearty Oatmeal   not_set"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
    "                                                  df.Score.values,\n",
    "                                                  test_size=0.15,\n",
    "                                                  random_state=17,\n",
    "                                                  stratify=df.Score.values)\n",
    "# create new column\n",
    "df['data_type'] = ['not_set'] * df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in data type\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>1929</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>340</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>1908</td>\n",
       "      <td>1908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>337</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>2243</td>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>396</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>2258</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>398</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>1804</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Text\n",
       "Score data_type            \n",
       "1     train      1929  1929\n",
       "      val         340   340\n",
       "2     train      1908  1908\n",
       "      val         337   337\n",
       "3     train      2243  2243\n",
       "      val         396   396\n",
       "4     train      2258  2258\n",
       "      val         398   398\n",
       "5     train      1804  1804\n",
       "      val         319   319"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Score','data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **`from transformers import BertTokenizer`**:\n",
    "   - `BertTokenizer` là một lớp từ thư viện Transformers của Hugging Face, được thiết kế để chuyển đổi văn bản thành đầu vào mà mô hình BERT có thể hiểu được. Nó cung cấp các phương thức để mã hóa văn bản thành các token và thêm các thông tin đặc biệt như token đặc biệt `[CLS]` và `[SEP]` sử dụng trong mô hình BERT.\n",
    "\n",
    "2. **`from torch.utils.data import TensorDataset`**:\n",
    "   - `TensorDataset` là một lớp từ thư viện torch, được sử dụng để tạo dataset cho PyTorch. Đây là một cách thuận tiện để tổ chức dữ liệu và truyền nó vào mô hình PyTorch. Lớp này chấp nhận một hoặc nhiều tensors và tạo ra một dataset với khả năng lập chỉ mục dữ liệu.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_text = max(len(text) for text in df.Text)\n",
    "max_len_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Work_Space\\ML\\final_project\\Mashine-Learning---RoBerta---Base-Bert\\venv390\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize train set\n",
    "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].Text.values,\n",
    "                                                 add_special_tokens=True,\n",
    "                                                 return_attention_mask=True,\n",
    "                                                 pad_to_max_length=True,\n",
    "                                                 max_length=max_len_text+1,\n",
    "                                                 return_tensors='pt',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer val set\n",
    "encoded_data_val = tokenizer.batch_encode_plus(df[df.data_type == 'val'].Text.values,\n",
    "                                               # add_special_tokens = True,\n",
    "                                               return_attention_mask=True,\n",
    "                                               pad_to_max_length=True,\n",
    "                                               max_length=max_len_text+1,\n",
    "                                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2204,  3737,  ...,     0,     0,     0],\n",
       "        [  101,  2025,  2004,  ...,     0,     0,     0],\n",
       "        [  101,  1000, 12208,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  9364,   102,  ...,     0,     0,     0],\n",
       "        [  101,  5440,  2731,  ...,     0,     0,     0],\n",
       "        [  101,  2307,  6861,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode train set\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == 'train'].Score.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode val set\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "\n",
    "# convert data type to torch.tensor\n",
    "labels_val = torch.tensor(df[df.data_type == 'val'].Score.values, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2204,  3737,  ...,     0,     0,     0],\n",
       "        [  101,  2025,  2004,  ...,     0,     0,     0],\n",
       "        [  101,  1000, 12208,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  9364,   102,  ...,     0,     0,     0],\n",
       "        [  101,  5440,  2731,  ...,     0,     0,     0],\n",
       "        [  101,  2307,  6861,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 1, 4,  ..., 2, 5, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "dataset_train = TensorDataset(input_ids_train,\n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val,\n",
    "                            attention_masks_val,\n",
    "                            labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10142\n",
      "1790\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<torch.utils.data.dataset.TensorDataset object at 0x0000021A81DAC910>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  2204,  3737,  ...,     0,     0,     0],\n",
       "         [  101,  2025,  2004,  ...,     0,     0,     0],\n",
       "         [  101,  1000, 12208,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  9364,   102,  ...,     0,     0,     0],\n",
       "         [  101,  5440,  2731,  ...,     0,     0,     0],\n",
       "         [  101,  2307,  6861,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([5, 1, 4,  ..., 2, 5, 5]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(df.Score.unique())+1,\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\",\n",
       "    \"3\": \"LABEL_3\",\n",
       "    \"4\": \"LABEL_4\",\n",
       "    \"5\": \"LABEL_5\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2,\n",
       "    \"LABEL_3\": 3,\n",
       "    \"LABEL_4\": 4,\n",
       "    \"LABEL_5\": 5\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.35.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# We Need two different dataloder\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler=RandomSampler(dataset_train),\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=10,\n",
    "                                pin_memory=True\n",
    "\n",
    "                              )\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val,\n",
    "                                   sampler=RandomSampler(dataset_val),\n",
    "                                   batch_size=batch_size,\n",
    "                                   num_workers=10,\n",
    "                                   pin_memory=True\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_train.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setting Up Optimiser and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Work_Space\\ML\\final_project\\Mashine-Learning---RoBerta---Base-Bert\\venv390\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "\n",
    "    # Setting up the preds to axis=1\n",
    "    # Flatting it to a single iterable list of array\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "\n",
    "    # Flattening the labels\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Returning the f1_score as define by sklearn\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'sad': 2,\n",
    "              'worry': 3,\n",
    "              'so sad': 1,\n",
    "              'happy': 4,\n",
    "              'so happy': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    # Iterating over all the unique labels\n",
    "    # label_flat are the --> True labels\n",
    "    for label in np.unique(labels_flat):\n",
    "        # Taking out all the pred_flat where the True alable is the lable we care about.\n",
    "        # e.g. for the label Happy -- we Takes all Prediction for true happy flag\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create a training loop to control PyTorch finetuning of BERT using CPU or GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val, model=model):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in tqdm(dataloader_val):\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                  }\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val)\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messure step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, epochs+1):\n",
    "#     # Set model in train mode\n",
    "\n",
    "#     model.train()\n",
    "\n",
    "#     # Tracking variable\n",
    "#     loss_train_total = 0\n",
    "#     print(f'Epoch {epoch}')\n",
    "#     # set up progress bar\n",
    "#     progress_bar = tqdm(dataloader_train,\n",
    "#                         desc='Epoch {:1d}'.format(epoch),\n",
    "#                         leave=False,\n",
    "#                         disable=False)\n",
    "#     for batch in progress_bar:\n",
    "#         # Set gradient to 0\n",
    "#         model.zero_grad()\n",
    "#         # Load into GPU\n",
    "#         batch = tuple(b.to(device) for b in batch)\n",
    "#         # Define inputs\n",
    "#         inputs = {'input_ids': batch[0],\n",
    "#                   'attention_mask': batch[1],\n",
    "#                   'labels': batch[2]}\n",
    "#         outputs = model(**inputs)\n",
    "#         loss = outputs[0]  # output.loss\n",
    "#         loss_train_total += loss.item()\n",
    "#         # Backward pass to get gradients\n",
    "#         loss.backward()\n",
    "#         # Clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "#         # Update optimizer\n",
    "#         optimizer.step()\n",
    "#         # Update scheduler\n",
    "\n",
    "#         scheduler.step()\n",
    "#         print(f'Training loss: {loss.item()/len(batch)}')\n",
    "#         # break\n",
    "\n",
    "\n",
    "\n",
    "#     model_save_path = f'./model/pretrained_bert_model_{epoch}.pt'\n",
    "\n",
    "#     torch.save(model, model_save_path)\n",
    "\n",
    "\n",
    "#     # Print training result\n",
    "#     loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "\n",
    "#     print(f'Training loss: {loss_train_avg}')\n",
    "#     # Evaluate\n",
    "#     val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "#     # F1 score\n",
    "#     val_f1 = f1_score_func(predictions, true_vals)\n",
    "#     print(f'Validation loss: {val_loss}')\n",
    "#     print(f'F1 Score (weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Đường dẫn đến tệp .pt đã lưu\n",
    "model_path = '../model/pretrained_bert_model_1.pt'\n",
    "\n",
    "# Khởi tạo mô hình BERT cho phân loại chuỗi và tải trạng thái từ tệp đã lưu\n",
    "load_model = torch.load(model_path)\n",
    "\n",
    "load_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb69021ee754adb899cea8980d0c77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate\n",
    "_, predictions, true_vals = evaluate(dataloader_validation, load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: so sad\n",
      "Accuracy: 212/340\n",
      "\n",
      "Class: sad\n",
      "Accuracy: 82/337\n",
      "\n",
      "Class: worry\n",
      "Accuracy: 195/396\n",
      "\n",
      "Class: happy\n",
      "Accuracy: 216/398\n",
      "\n",
      "Class: so happy\n",
      "Accuracy: 195/319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get accuracy score\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
